{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with product reviews from Amazon España"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise takes over 700,000 Amazon product reviews and trains a model in order to perform sentiment analysis on comments, determining if they are positive or negative\n",
    "\n",
    "+ The number of stars given to a product will determine whether this comment is positive or negative. We are goin to take 4 and 5 star ratings as positive and 3 and below as negative\n",
    "\n",
    "We are going to use a bag of words approach, which means that we are going to count the number of times each word appears in each comment and those will be our input variables or features. Our aoutput will be a binary variable (0 or 1) stating if the comment is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# We will follow the following steps:\n",
    "\n",
    "1. Read the dataset\n",
    "2. Divide the sample in training and test\n",
    "3. Apply \"HashVectorizer\" to the training set, which counts the times a word appears in each comment. For each comment, a numerical vector is created with the number of times each word appears.\n",
    "The vectorizer includes data preparation:\n",
    "- A function that cleans a prepares the data with a Stemming in Spanish.\n",
    "- I initially used a stop-word removal function, but I realized the model performed better without this.\n",
    "4. Apply and compare different classification models, using cross-validation. I have chosen 2 types of models: Logistic Regression and Linear SCV. we are going to compare the performance of the models on the testing dataset. At the end, the best model will be trained with all the data (training and testing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Python path is /Users/manena/PYTHON DATAHACK/Practicas/Practicas_Maria_Elena_Martinez\n"
     ]
    }
   ],
   "source": [
    "#1. Reading the data\n",
    "\n",
    "import os\n",
    "\n",
    "current_path = os.path.abspath(os.curdir)\n",
    "\n",
    "print(\"The current Python path is \" + current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "amazon_es_reviews.csv                          2016-06-08 01:52:20    194495085\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "# El archivo debe estar en el directorio actual\n",
    "zip_file = open(\"amazon_es_reviews.csv.zip\", \"rb\")\n",
    "\n",
    "inst_zip_file = zipfile.ZipFile(zip_file)\n",
    "inst_zip_file.printdir()\n",
    "inst_zip_file.extractall(current_path)\n",
    "\n",
    "\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_reviews = pd.DataFrame()\n",
    "df_reviews = pd.read_csv(\"amazon_es_reviews.csv\", sep=\";\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comentario</th>\n",
       "      <th>estrellas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para chicas es perfecto, ya que la esfera no e...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muy floja la cuerda y el anclaje es de mala ca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Razonablemente bien escrito, bien ambientado, ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hola! No suel o escribir muchas opiniones sobr...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A simple vista m parecia una buena camara pero...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NI para pasar el rato, los personajes no tiene...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>el fabricante decia que es compatible con la d...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>el libro está en muy buenas condiciones, pero ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buen aspecto, pero le falta fortaleza. util pa...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Explica de forma simple y sencilla los pensami...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comentario  estrellas\n",
       "0  Para chicas es perfecto, ya que la esfera no e...        4.0\n",
       "1  Muy floja la cuerda y el anclaje es de mala ca...        1.0\n",
       "2  Razonablemente bien escrito, bien ambientado, ...        3.0\n",
       "3  Hola! No suel o escribir muchas opiniones sobr...        5.0\n",
       "4  A simple vista m parecia una buena camara pero...        1.0\n",
       "5  NI para pasar el rato, los personajes no tiene...        1.0\n",
       "6  el fabricante decia que es compatible con la d...        2.0\n",
       "7  el libro está en muy buenas condiciones, pero ...        3.0\n",
       "8  buen aspecto, pero le falta fortaleza. util pa...        3.0\n",
       "9  Explica de forma simple y sencilla los pensami...        5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download_shell() #This line should be uncommented if you have never installed nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manena/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 2. Dividir la muestra en training y testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(df_reviews,\n",
    "                              train_size=0.8,\n",
    "                              test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply a Stemmer in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "my_tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "\n",
    "# Our stemmer...\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "\n",
    "stemmer_castellano = SpanishStemmer()\n",
    "\n",
    "\n",
    "# The function that performs tokenization and stemming...\n",
    "def tokenizer_stemmer(document):\n",
    "    return [stemmer_castellano.stem(token) for token in my_tokenizer.tokenize(document)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# We initialize the \"HashingVectorizer\", a scikit-learn tool for \"bag of words\".  \n",
    "vectorizer = HashingVectorizer(analyzer = \"word\",   # wor level analysis\n",
    "                             tokenizer = tokenizer_stemmer,# We prepare the data with the function we've just defined\n",
    "                             preprocessor = None, \n",
    "                           #  stop_words = stopwords.words(\"spanish\"),# we no longer elimitane stopwords\n",
    "                             n_features = 10000, # Max number of features = 10000\n",
    "                             strip_accents='ascii', # we eliminate Spanish accents\n",
    "                             encoding = 'utf-8',\n",
    "                             ngram_range = (1,3)) # We use individual words, bigrams and trigrams\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We obtain the bag of words of the training dataset\n",
    "train_data_features = vectorizer.fit_transform(pd.DataFrame(train).loc[:,\"comentario\"])\n",
    "# (this will take long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The target variable is = 0 if the comment has 3 or less stars and =1 if it has 4 or 5 stars\n",
    "# (0: negative comment, 1: positive comment)\n",
    "train_target = [1 if x > 3 else 0 for x in train[\"estrellas\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561956, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Let's have an idea of the dimensions of the results\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('regresion', LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We make a pipeline to enter it in the GridSearchCV and compare the model with different parameters\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_regression = LogisticRegressionCV()\n",
    "\n",
    "# We generate the Pipeline\n",
    "log_pipeline = Pipeline(steps=[(\"regresion\",log_regression)])\n",
    "\n",
    "log_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the hiperparameters (Very simple because of memory issues)\n",
    "hiperparam_pipeline_log_reg = {  \n",
    "   \"regresion__fit_intercept\":[True], # Data is not centered\n",
    "   \"regresion__cv\":[10, 20],\n",
    "   \"regresion__max_iter\": [500, 600]\n",
    "    }\n",
    "                             \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('regresion', LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'regresion__fit_intercept': [True], 'regresion__cv': [10, 20], 'regresion__max_iter': [500, 600]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid_search = GridSearchCV(estimator=log_pipeline,\n",
    "                              param_grid=hiperparam_pipeline_log_reg,\n",
    "                              scoring=\"roc_auc\",\n",
    "                              cv=10,\n",
    "                              n_jobs=4\n",
    "                             )\n",
    "        \n",
    "\n",
    "#We train the model\n",
    "log_grid_search.fit( train_data_features, \n",
    "                    train_target)\n",
    "\n",
    "#This will take a very long time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to compare, we transform the test set with the vectorizer and run the model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(test[\"comentario\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_target = [1 if x > 3 else 0 for x in test[\"estrellas\"] ]\n",
    "score = log_grid_search.score(test_data_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897634145407\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The score is an area under the ROC curve of 89.76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We make tests\n",
    "phrases = [\"es perfecta para salir a pasear\",\n",
    "         \"lo odio\",\n",
    "         \"lo recomiendo a mis amigos, está muy bien\"]\n",
    "my_vector = vectorizer.transform(phrases)\n",
    "log_grid_search.predict(my_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 39 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we're going to try with a LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "Cs = np.logspace(-2, 4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('svc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcLinear = LinearSVC()\n",
    "svc_pipeline = Pipeline(steps=[(\"svc\",svcLinear)])\n",
    "\n",
    "svc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hiperparam_pipeline_svc = {  \n",
    "    \"svc__fit_intercept\":[True], # Data is not centered\n",
    "    \"svc__max_iter\": [600,500,400], # Trying different values, these were the best numbers of iterations\n",
    "    \"svc__C\": Cs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('svc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'svc__fit_intercept': [True], 'svc__max_iter': [600, 500, 400], 'svc__C': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02,   1.00000e+03,   1.00000e+04])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid_search = GridSearchCV(estimator=svc_pipeline,\n",
    "                              param_grid=hiperparam_pipeline_svc,\n",
    "                              scoring=\"roc_auc\",\n",
    "                              cv=10,\n",
    "                              n_jobs=4\n",
    "                             )\n",
    "        \n",
    "\n",
    "#We train the model\n",
    "svc_grid_search.fit( train_data_features, \n",
    "                    train_target)\n",
    "#(it takes a long time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get the LinearSVCs scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_svc = svc_grid_search.score(test_data_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897425783599\n"
     ]
    }
   ],
   "source": [
    "print(score_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('svc', LinearSVC(C=0.10000000000000001, class_weight=None, dual=True,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=500, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# We choose the Linear SVC (score of 89.74%) because it trains faster and the difference with Logistic Regression is not big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[-1.64516276 -1.5424808   0.09425527]\n",
      "[0 0 1]\n",
      "[[ 0.9883025   0.0116975 ]\n",
      " [ 0.98531999  0.01468001]\n",
      " [ 0.43809482  0.56190518]]\n"
     ]
    }
   ],
   "source": [
    "phrases = [\"no me gusta nada\",\n",
    "          \"no lo recomiendo\",          \n",
    "          \"lo usaré toda la vida\"]\n",
    "\n",
    "my_vector = vectorizer.transform(phrases)\n",
    "class1 = svc_grid_search.predict(my_vector)\n",
    "prediction1 = svc_grid_search.decision_function(my_vector)\n",
    "\n",
    "class2 = log_grid_search.predict(my_vector)\n",
    "prediction2 = log_grid_search.predict_proba(my_vector)\n",
    "\n",
    "print(class1)\n",
    "print(prediction1)\n",
    "\n",
    "print(class2)\n",
    "print(prediction2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We train the best model with the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_features = vectorizer.fit_transform(df_reviews.loc[:,\"comentario\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_target = [1 if x > 3 else 0 for x in df_reviews[\"estrellas\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('svc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcLinear = LinearSVC()\n",
    "svc_pipeline = Pipeline(steps=[(\"svc\",svcLinear)])\n",
    "\n",
    "svc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparam_pipeline_svc = {  \n",
    "   \"svc__fit_intercept\":[True], # Porque los datos no están centrados\n",
    "   \"svc__max_iter\": [500],\n",
    "   \"svc__C\": [0.1] \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('svc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'svc__fit_intercept': [True], 'svc__max_iter': [500], 'svc__C': [0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid_search = GridSearchCV(estimator=svc_pipeline,\n",
    "                              param_grid=hiperparam_pipeline_svc,\n",
    "                              scoring=\"roc_auc\",\n",
    "                              cv=10,\n",
    "                              n_jobs=4\n",
    "                             )\n",
    "        \n",
    "\n",
    "#Se entrena \n",
    "svc_grid_search.fit( all_data_features, \n",
    "                    all_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We finally store the model and the vectorizer in a pickle in order to use it on a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the model in a pickle\n",
    "import joblib\n",
    "filename = \"best_model.pkl\"\n",
    "with open(filename, 'wb') as fo:  \n",
    "    joblib.dump(svc_grid_search, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We remove the tokenizer from the data preparer we are going to store for using it on pythonanywhere\n",
    "#we will execute the tokenizer on the input phrase before applying the model\n",
    "#(For some reason, there is an error on pythonanywhere if we try to tokenize from the pickle stored vectorizer)\n",
    "vectorizer.tokenizer = None \n",
    "\n",
    "filename = \"prepare_data_no_tokenizer.pkl\"\n",
    "with open(filename, 'wb') as fo:  \n",
    "    joblib.dump(vectorizer, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
